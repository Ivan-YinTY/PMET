{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T07:58:18.346353Z",
     "iopub.status.busy": "2024-04-04T07:58:18.345902Z",
     "iopub.status.idle": "2024-04-04T07:58:19.009682Z",
     "shell.execute_reply": "2024-04-04T07:58:19.009050Z",
     "shell.execute_reply.started": "2024-04-04T07:58:18.346322Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "# Scienfitic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "torch.cuda.set_device(1)\n",
    "from tqdm import tqdm\n",
    "torch.set_grad_enabled(False)\n",
    "tqdm.pandas()\n",
    "\n",
    "# Visuals\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context=\"notebook\", \n",
    "        rc={\"font.size\":16,\n",
    "            \"axes.titlesize\":16,\n",
    "            \"axes.labelsize\":16,\n",
    "            \"xtick.labelsize\": 16.0,\n",
    "            \"ytick.labelsize\": 16.0,\n",
    "            \"legend.fontsize\": 16.0})\n",
    "palette_ = sns.color_palette(\"Set1\")\n",
    "palette = palette_[2:5] + palette_[7:]\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Utilities\n",
    "from utils import (\n",
    "    ModelAndTokenizer,\n",
    "    make_inputs,\n",
    "    decode_tokens,\n",
    "    find_token_range,\n",
    "    predict_from_input,\n",
    ")\n",
    "import nethook\n",
    "# List of stopwords from NLTK, needed only for the attributes rate evaluation.\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# from nltk.corpus import stopwords\n",
    "# stopwords0_ = stopwords.words('english')\n",
    "# stopwords0_ = {word: \"\" for word in stopwords0_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T07:58:21.396088Z",
     "iopub.status.busy": "2024-04-04T07:58:21.395368Z",
     "iopub.status.idle": "2024-04-04T07:58:21.411979Z",
     "shell.execute_reply": "2024-04-04T07:58:21.411548Z",
     "shell.execute_reply.started": "2024-04-04T07:58:21.396056Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get CounterFact data for GPT2-xl, from the ROME repository.\n",
    "knowns_df = pd.read_json(\"../memit_attn/data/known_1000.json\")\n",
    "knowns_df_size = len(knowns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T07:58:23.720245Z",
     "iopub.status.busy": "2024-04-04T07:58:23.719889Z",
     "iopub.status.idle": "2024-04-04T07:58:32.987567Z",
     "shell.execute_reply": "2024-04-04T07:58:32.987012Z",
     "shell.execute_reply.started": "2024-04-04T07:58:23.720216Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c62bf275c8f42738181e0d02d890363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load model from local\n",
    "model_path = \"/openbayes/input/input0/\"\n",
    "# model_path = \"None\"\n",
    "# model_name = \"Llama-2-7b-chat-hf\"\n",
    "mt = ModelAndTokenizer(\n",
    "    model_path,\n",
    "    low_cpu_mem_usage=False,\n",
    "    torch_dtype=torch.half,\n",
    ")\n",
    "mt.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "\n",
    "#本地模型路径\n",
    "model_path = \"/openbayes/input/input0\"\n",
    "# model_path = \"E:\\\\work\\\\AI\\\\GPT\\\\llama_model_7b_8bit\"\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.device_count())\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "else:\n",
    "    print('没有GPU')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "if model_path.endswith(\"4bit\"):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            load_in_4bit=True,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map='auto'\n",
    "        )\n",
    "elif model_path.endswith(\"8bit\"):\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            load_in_8bit=True,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map='auto'\n",
    "        )\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path).cuda()\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "instruction = \"\"\"[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "            If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n<</SYS>>\\n\\n{} [/INST]\"\"\"\n",
    "\n",
    "prompt = instruction.format(\"Hello, what the meaning of life？\")\n",
    "generate_ids = model.generate(tokenizer(prompt, return_tensors='pt').input_ids.cuda(), max_new_tokens=4096, streamer=streamer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache of hidden representations of GPT-J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T08:02:34.428204Z",
     "iopub.status.busy": "2024-04-04T08:02:34.427779Z",
     "iopub.status.idle": "2024-04-04T08:02:34.436730Z",
     "shell.execute_reply": "2024-04-04T08:02:34.435556Z",
     "shell.execute_reply.started": "2024-04-04T08:02:34.428174Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model\n",
      "model.embed_tokens\n",
      "model.layers\n",
      "model.layers.0\n",
      "model.layers.0.self_attn\n",
      "model.layers.0.self_attn.q_proj\n",
      "model.layers.0.self_attn.k_proj\n",
      "model.layers.0.self_attn.v_proj\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.0.self_attn.rotary_emb\n",
      "model.layers.0.mlp\n",
      "model.layers.0.mlp.gate_proj\n",
      "model.layers.0.mlp.up_proj\n",
      "model.layers.0.mlp.down_proj\n",
      "model.layers.0.mlp.act_fn\n",
      "model.layers.0.input_layernorm\n",
      "model.layers.0.post_attention_layernorm\n",
      "model.layers.1\n",
      "model.layers.1.self_attn\n",
      "model.layers.1.self_attn.q_proj\n",
      "model.layers.1.self_attn.k_proj\n",
      "model.layers.1.self_attn.v_proj\n",
      "model.layers.1.self_attn.o_proj\n",
      "model.layers.1.self_attn.rotary_emb\n",
      "model.layers.1.mlp\n",
      "model.layers.1.mlp.gate_proj\n",
      "model.layers.1.mlp.up_proj\n",
      "model.layers.1.mlp.down_proj\n",
      "model.layers.1.mlp.act_fn\n",
      "model.layers.1.input_layernorm\n",
      "model.layers.1.post_attention_layernorm\n",
      "model.layers.2\n",
      "model.layers.2.self_attn\n",
      "model.layers.2.self_attn.q_proj\n",
      "model.layers.2.self_attn.k_proj\n",
      "model.layers.2.self_attn.v_proj\n",
      "model.layers.2.self_attn.o_proj\n",
      "model.layers.2.self_attn.rotary_emb\n",
      "model.layers.2.mlp\n",
      "model.layers.2.mlp.gate_proj\n",
      "model.layers.2.mlp.up_proj\n",
      "model.layers.2.mlp.down_proj\n",
      "model.layers.2.mlp.act_fn\n",
      "model.layers.2.input_layernorm\n",
      "model.layers.2.post_attention_layernorm\n",
      "model.layers.3\n",
      "model.layers.3.self_attn\n",
      "model.layers.3.self_attn.q_proj\n",
      "model.layers.3.self_attn.k_proj\n",
      "model.layers.3.self_attn.v_proj\n",
      "model.layers.3.self_attn.o_proj\n",
      "model.layers.3.self_attn.rotary_emb\n",
      "model.layers.3.mlp\n",
      "model.layers.3.mlp.gate_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.3.mlp.down_proj\n",
      "model.layers.3.mlp.act_fn\n",
      "model.layers.3.input_layernorm\n",
      "model.layers.3.post_attention_layernorm\n",
      "model.layers.4\n",
      "model.layers.4.self_attn\n",
      "model.layers.4.self_attn.q_proj\n",
      "model.layers.4.self_attn.k_proj\n",
      "model.layers.4.self_attn.v_proj\n",
      "model.layers.4.self_attn.o_proj\n",
      "model.layers.4.self_attn.rotary_emb\n",
      "model.layers.4.mlp\n",
      "model.layers.4.mlp.gate_proj\n",
      "model.layers.4.mlp.up_proj\n",
      "model.layers.4.mlp.down_proj\n",
      "model.layers.4.mlp.act_fn\n",
      "model.layers.4.input_layernorm\n",
      "model.layers.4.post_attention_layernorm\n",
      "model.layers.5\n",
      "model.layers.5.self_attn\n",
      "model.layers.5.self_attn.q_proj\n",
      "model.layers.5.self_attn.k_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.self_attn.o_proj\n",
      "model.layers.5.self_attn.rotary_emb\n",
      "model.layers.5.mlp\n",
      "model.layers.5.mlp.gate_proj\n",
      "model.layers.5.mlp.up_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.5.mlp.act_fn\n",
      "model.layers.5.input_layernorm\n",
      "model.layers.5.post_attention_layernorm\n",
      "model.layers.6\n",
      "model.layers.6.self_attn\n",
      "model.layers.6.self_attn.q_proj\n",
      "model.layers.6.self_attn.k_proj\n",
      "model.layers.6.self_attn.v_proj\n",
      "model.layers.6.self_attn.o_proj\n",
      "model.layers.6.self_attn.rotary_emb\n",
      "model.layers.6.mlp\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.6.mlp.up_proj\n",
      "model.layers.6.mlp.down_proj\n",
      "model.layers.6.mlp.act_fn\n",
      "model.layers.6.input_layernorm\n",
      "model.layers.6.post_attention_layernorm\n",
      "model.layers.7\n",
      "model.layers.7.self_attn\n",
      "model.layers.7.self_attn.q_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.7.self_attn.v_proj\n",
      "model.layers.7.self_attn.o_proj\n",
      "model.layers.7.self_attn.rotary_emb\n",
      "model.layers.7.mlp\n",
      "model.layers.7.mlp.gate_proj\n",
      "model.layers.7.mlp.up_proj\n",
      "model.layers.7.mlp.down_proj\n",
      "model.layers.7.mlp.act_fn\n",
      "model.layers.7.input_layernorm\n",
      "model.layers.7.post_attention_layernorm\n",
      "model.layers.8\n",
      "model.layers.8.self_attn\n",
      "model.layers.8.self_attn.q_proj\n",
      "model.layers.8.self_attn.k_proj\n",
      "model.layers.8.self_attn.v_proj\n",
      "model.layers.8.self_attn.o_proj\n",
      "model.layers.8.self_attn.rotary_emb\n",
      "model.layers.8.mlp\n",
      "model.layers.8.mlp.gate_proj\n",
      "model.layers.8.mlp.up_proj\n",
      "model.layers.8.mlp.down_proj\n",
      "model.layers.8.mlp.act_fn\n",
      "model.layers.8.input_layernorm\n",
      "model.layers.8.post_attention_layernorm\n",
      "model.layers.9\n",
      "model.layers.9.self_attn\n",
      "model.layers.9.self_attn.q_proj\n",
      "model.layers.9.self_attn.k_proj\n",
      "model.layers.9.self_attn.v_proj\n",
      "model.layers.9.self_attn.o_proj\n",
      "model.layers.9.self_attn.rotary_emb\n",
      "model.layers.9.mlp\n",
      "model.layers.9.mlp.gate_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.9.mlp.down_proj\n",
      "model.layers.9.mlp.act_fn\n",
      "model.layers.9.input_layernorm\n",
      "model.layers.9.post_attention_layernorm\n",
      "model.layers.10\n",
      "model.layers.10.self_attn\n",
      "model.layers.10.self_attn.q_proj\n",
      "model.layers.10.self_attn.k_proj\n",
      "model.layers.10.self_attn.v_proj\n",
      "model.layers.10.self_attn.o_proj\n",
      "model.layers.10.self_attn.rotary_emb\n",
      "model.layers.10.mlp\n",
      "model.layers.10.mlp.gate_proj\n",
      "model.layers.10.mlp.up_proj\n",
      "model.layers.10.mlp.down_proj\n",
      "model.layers.10.mlp.act_fn\n",
      "model.layers.10.input_layernorm\n",
      "model.layers.10.post_attention_layernorm\n",
      "model.layers.11\n",
      "model.layers.11.self_attn\n",
      "model.layers.11.self_attn.q_proj\n",
      "model.layers.11.self_attn.k_proj\n",
      "model.layers.11.self_attn.v_proj\n",
      "model.layers.11.self_attn.o_proj\n",
      "model.layers.11.self_attn.rotary_emb\n",
      "model.layers.11.mlp\n",
      "model.layers.11.mlp.gate_proj\n",
      "model.layers.11.mlp.up_proj\n",
      "model.layers.11.mlp.down_proj\n",
      "model.layers.11.mlp.act_fn\n",
      "model.layers.11.input_layernorm\n",
      "model.layers.11.post_attention_layernorm\n",
      "model.layers.12\n",
      "model.layers.12.self_attn\n",
      "model.layers.12.self_attn.q_proj\n",
      "model.layers.12.self_attn.k_proj\n",
      "model.layers.12.self_attn.v_proj\n",
      "model.layers.12.self_attn.o_proj\n",
      "model.layers.12.self_attn.rotary_emb\n",
      "model.layers.12.mlp\n",
      "model.layers.12.mlp.gate_proj\n",
      "model.layers.12.mlp.up_proj\n",
      "model.layers.12.mlp.down_proj\n",
      "model.layers.12.mlp.act_fn\n",
      "model.layers.12.input_layernorm\n",
      "model.layers.12.post_attention_layernorm\n",
      "model.layers.13\n",
      "model.layers.13.self_attn\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.13.self_attn.k_proj\n",
      "model.layers.13.self_attn.v_proj\n",
      "model.layers.13.self_attn.o_proj\n",
      "model.layers.13.self_attn.rotary_emb\n",
      "model.layers.13.mlp\n",
      "model.layers.13.mlp.gate_proj\n",
      "model.layers.13.mlp.up_proj\n",
      "model.layers.13.mlp.down_proj\n",
      "model.layers.13.mlp.act_fn\n",
      "model.layers.13.input_layernorm\n",
      "model.layers.13.post_attention_layernorm\n",
      "model.layers.14\n",
      "model.layers.14.self_attn\n",
      "model.layers.14.self_attn.q_proj\n",
      "model.layers.14.self_attn.k_proj\n",
      "model.layers.14.self_attn.v_proj\n",
      "model.layers.14.self_attn.o_proj\n",
      "model.layers.14.self_attn.rotary_emb\n",
      "model.layers.14.mlp\n",
      "model.layers.14.mlp.gate_proj\n",
      "model.layers.14.mlp.up_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.14.mlp.act_fn\n",
      "model.layers.14.input_layernorm\n",
      "model.layers.14.post_attention_layernorm\n",
      "model.layers.15\n",
      "model.layers.15.self_attn\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.15.self_attn.k_proj\n",
      "model.layers.15.self_attn.v_proj\n",
      "model.layers.15.self_attn.o_proj\n",
      "model.layers.15.self_attn.rotary_emb\n",
      "model.layers.15.mlp\n",
      "model.layers.15.mlp.gate_proj\n",
      "model.layers.15.mlp.up_proj\n",
      "model.layers.15.mlp.down_proj\n",
      "model.layers.15.mlp.act_fn\n",
      "model.layers.15.input_layernorm\n",
      "model.layers.15.post_attention_layernorm\n",
      "model.layers.16\n",
      "model.layers.16.self_attn\n",
      "model.layers.16.self_attn.q_proj\n",
      "model.layers.16.self_attn.k_proj\n",
      "model.layers.16.self_attn.v_proj\n",
      "model.layers.16.self_attn.o_proj\n",
      "model.layers.16.self_attn.rotary_emb\n",
      "model.layers.16.mlp\n",
      "model.layers.16.mlp.gate_proj\n",
      "model.layers.16.mlp.up_proj\n",
      "model.layers.16.mlp.down_proj\n",
      "model.layers.16.mlp.act_fn\n",
      "model.layers.16.input_layernorm\n",
      "model.layers.16.post_attention_layernorm\n",
      "model.layers.17\n",
      "model.layers.17.self_attn\n",
      "model.layers.17.self_attn.q_proj\n",
      "model.layers.17.self_attn.k_proj\n",
      "model.layers.17.self_attn.v_proj\n",
      "model.layers.17.self_attn.o_proj\n",
      "model.layers.17.self_attn.rotary_emb\n",
      "model.layers.17.mlp\n",
      "model.layers.17.mlp.gate_proj\n",
      "model.layers.17.mlp.up_proj\n",
      "model.layers.17.mlp.down_proj\n",
      "model.layers.17.mlp.act_fn\n",
      "model.layers.17.input_layernorm\n",
      "model.layers.17.post_attention_layernorm\n",
      "model.layers.18\n",
      "model.layers.18.self_attn\n",
      "model.layers.18.self_attn.q_proj\n",
      "model.layers.18.self_attn.k_proj\n",
      "model.layers.18.self_attn.v_proj\n",
      "model.layers.18.self_attn.o_proj\n",
      "model.layers.18.self_attn.rotary_emb\n",
      "model.layers.18.mlp\n",
      "model.layers.18.mlp.gate_proj\n",
      "model.layers.18.mlp.up_proj\n",
      "model.layers.18.mlp.down_proj\n",
      "model.layers.18.mlp.act_fn\n",
      "model.layers.18.input_layernorm\n",
      "model.layers.18.post_attention_layernorm\n",
      "model.layers.19\n",
      "model.layers.19.self_attn\n",
      "model.layers.19.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.self_attn.v_proj\n",
      "model.layers.19.self_attn.o_proj\n",
      "model.layers.19.self_attn.rotary_emb\n",
      "model.layers.19.mlp\n",
      "model.layers.19.mlp.gate_proj\n",
      "model.layers.19.mlp.up_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.19.mlp.act_fn\n",
      "model.layers.19.input_layernorm\n",
      "model.layers.19.post_attention_layernorm\n",
      "model.layers.20\n",
      "model.layers.20.self_attn\n",
      "model.layers.20.self_attn.q_proj\n",
      "model.layers.20.self_attn.k_proj\n",
      "model.layers.20.self_attn.v_proj\n",
      "model.layers.20.self_attn.o_proj\n",
      "model.layers.20.self_attn.rotary_emb\n",
      "model.layers.20.mlp\n",
      "model.layers.20.mlp.gate_proj\n",
      "model.layers.20.mlp.up_proj\n",
      "model.layers.20.mlp.down_proj\n",
      "model.layers.20.mlp.act_fn\n",
      "model.layers.20.input_layernorm\n",
      "model.layers.20.post_attention_layernorm\n",
      "model.layers.21\n",
      "model.layers.21.self_attn\n",
      "model.layers.21.self_attn.q_proj\n",
      "model.layers.21.self_attn.k_proj\n",
      "model.layers.21.self_attn.v_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.self_attn.rotary_emb\n",
      "model.layers.21.mlp\n",
      "model.layers.21.mlp.gate_proj\n",
      "model.layers.21.mlp.up_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.21.mlp.act_fn\n",
      "model.layers.21.input_layernorm\n",
      "model.layers.21.post_attention_layernorm\n",
      "model.layers.22\n",
      "model.layers.22.self_attn\n",
      "model.layers.22.self_attn.q_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.self_attn.v_proj\n",
      "model.layers.22.self_attn.o_proj\n",
      "model.layers.22.self_attn.rotary_emb\n",
      "model.layers.22.mlp\n",
      "model.layers.22.mlp.gate_proj\n",
      "model.layers.22.mlp.up_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.22.mlp.act_fn\n",
      "model.layers.22.input_layernorm\n",
      "model.layers.22.post_attention_layernorm\n",
      "model.layers.23\n",
      "model.layers.23.self_attn\n",
      "model.layers.23.self_attn.q_proj\n",
      "model.layers.23.self_attn.k_proj\n",
      "model.layers.23.self_attn.v_proj\n",
      "model.layers.23.self_attn.o_proj\n",
      "model.layers.23.self_attn.rotary_emb\n",
      "model.layers.23.mlp\n",
      "model.layers.23.mlp.gate_proj\n",
      "model.layers.23.mlp.up_proj\n",
      "model.layers.23.mlp.down_proj\n",
      "model.layers.23.mlp.act_fn\n",
      "model.layers.23.input_layernorm\n",
      "model.layers.23.post_attention_layernorm\n",
      "model.layers.24\n",
      "model.layers.24.self_attn\n",
      "model.layers.24.self_attn.q_proj\n",
      "model.layers.24.self_attn.k_proj\n",
      "model.layers.24.self_attn.v_proj\n",
      "model.layers.24.self_attn.o_proj\n",
      "model.layers.24.self_attn.rotary_emb\n",
      "model.layers.24.mlp\n",
      "model.layers.24.mlp.gate_proj\n",
      "model.layers.24.mlp.up_proj\n",
      "model.layers.24.mlp.down_proj\n",
      "model.layers.24.mlp.act_fn\n",
      "model.layers.24.input_layernorm\n",
      "model.layers.24.post_attention_layernorm\n",
      "model.layers.25\n",
      "model.layers.25.self_attn\n",
      "model.layers.25.self_attn.q_proj\n",
      "model.layers.25.self_attn.k_proj\n",
      "model.layers.25.self_attn.v_proj\n",
      "model.layers.25.self_attn.o_proj\n",
      "model.layers.25.self_attn.rotary_emb\n",
      "model.layers.25.mlp\n",
      "model.layers.25.mlp.gate_proj\n",
      "model.layers.25.mlp.up_proj\n",
      "model.layers.25.mlp.down_proj\n",
      "model.layers.25.mlp.act_fn\n",
      "model.layers.25.input_layernorm\n",
      "model.layers.25.post_attention_layernorm\n",
      "model.layers.26\n",
      "model.layers.26.self_attn\n",
      "model.layers.26.self_attn.q_proj\n",
      "model.layers.26.self_attn.k_proj\n",
      "model.layers.26.self_attn.v_proj\n",
      "model.layers.26.self_attn.o_proj\n",
      "model.layers.26.self_attn.rotary_emb\n",
      "model.layers.26.mlp\n",
      "model.layers.26.mlp.gate_proj\n",
      "model.layers.26.mlp.up_proj\n",
      "model.layers.26.mlp.down_proj\n",
      "model.layers.26.mlp.act_fn\n",
      "model.layers.26.input_layernorm\n",
      "model.layers.26.post_attention_layernorm\n",
      "model.layers.27\n",
      "model.layers.27.self_attn\n",
      "model.layers.27.self_attn.q_proj\n",
      "model.layers.27.self_attn.k_proj\n",
      "model.layers.27.self_attn.v_proj\n",
      "model.layers.27.self_attn.o_proj\n",
      "model.layers.27.self_attn.rotary_emb\n",
      "model.layers.27.mlp\n",
      "model.layers.27.mlp.gate_proj\n",
      "model.layers.27.mlp.up_proj\n",
      "model.layers.27.mlp.down_proj\n",
      "model.layers.27.mlp.act_fn\n",
      "model.layers.27.input_layernorm\n",
      "model.layers.27.post_attention_layernorm\n",
      "model.layers.28\n",
      "model.layers.28.self_attn\n",
      "model.layers.28.self_attn.q_proj\n",
      "model.layers.28.self_attn.k_proj\n",
      "model.layers.28.self_attn.v_proj\n",
      "model.layers.28.self_attn.o_proj\n",
      "model.layers.28.self_attn.rotary_emb\n",
      "model.layers.28.mlp\n",
      "model.layers.28.mlp.gate_proj\n",
      "model.layers.28.mlp.up_proj\n",
      "model.layers.28.mlp.down_proj\n",
      "model.layers.28.mlp.act_fn\n",
      "model.layers.28.input_layernorm\n",
      "model.layers.28.post_attention_layernorm\n",
      "model.layers.29\n",
      "model.layers.29.self_attn\n",
      "model.layers.29.self_attn.q_proj\n",
      "model.layers.29.self_attn.k_proj\n",
      "model.layers.29.self_attn.v_proj\n",
      "model.layers.29.self_attn.o_proj\n",
      "model.layers.29.self_attn.rotary_emb\n",
      "model.layers.29.mlp\n",
      "model.layers.29.mlp.gate_proj\n",
      "model.layers.29.mlp.up_proj\n",
      "model.layers.29.mlp.down_proj\n",
      "model.layers.29.mlp.act_fn\n",
      "model.layers.29.input_layernorm\n",
      "model.layers.29.post_attention_layernorm\n",
      "model.layers.30\n",
      "model.layers.30.self_attn\n",
      "model.layers.30.self_attn.q_proj\n",
      "model.layers.30.self_attn.k_proj\n",
      "model.layers.30.self_attn.v_proj\n",
      "model.layers.30.self_attn.o_proj\n",
      "model.layers.30.self_attn.rotary_emb\n",
      "model.layers.30.mlp\n",
      "model.layers.30.mlp.gate_proj\n",
      "model.layers.30.mlp.up_proj\n",
      "model.layers.30.mlp.down_proj\n",
      "model.layers.30.mlp.act_fn\n",
      "model.layers.30.input_layernorm\n",
      "model.layers.30.post_attention_layernorm\n",
      "model.layers.31\n",
      "model.layers.31.self_attn\n",
      "model.layers.31.self_attn.q_proj\n",
      "model.layers.31.self_attn.k_proj\n",
      "model.layers.31.self_attn.v_proj\n",
      "model.layers.31.self_attn.o_proj\n",
      "model.layers.31.self_attn.rotary_emb\n",
      "model.layers.31.mlp\n",
      "model.layers.31.mlp.gate_proj\n",
      "model.layers.31.mlp.up_proj\n",
      "model.layers.31.mlp.down_proj\n",
      "model.layers.31.mlp.act_fn\n",
      "model.layers.31.input_layernorm\n",
      "model.layers.31.post_attention_layernorm\n",
      "model.norm\n",
      "lm_head\n"
     ]
    }
   ],
   "source": [
    "for name, module in mt.model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T08:07:07.770962Z",
     "iopub.status.busy": "2024-04-04T08:07:07.770531Z",
     "iopub.status.idle": "2024-04-04T08:09:09.737875Z",
     "shell.execute_reply": "2024-04-04T08:09:09.737323Z",
     "shell.execute_reply.started": "2024-04-04T08:07:07.770932Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1209it [02:01,  9.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67648"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a cache of subject representations\n",
    "def edit_output_fn(cur_out, cur_layer):\n",
    "    return cur_out\n",
    "E = mt.model.get_output_embeddings().weight.detach()\n",
    "# ln_f = nethook.get_module(mt.model, \"transformer.ln_f\")\n",
    "ln_f = nethook.get_module(mt.model, \"model.norm\")\n",
    "\n",
    "mlp_module_tmp = \"model.layers.{}.mlp\"\n",
    "attn_module_tmp = \"model.layers.{}.self_attn\"\n",
    "layers_to_cache = range(0,28)\n",
    "layers_to_trace = []\n",
    "\n",
    "# 使用for循环将layers_to_cache列表中的每个层添加到要追踪的列表中\n",
    "for layer in layers_to_cache:\n",
    "    layers_to_trace.append(mlp_module_tmp.format(layer))\n",
    "    layers_to_trace.append(attn_module_tmp.format(layer))\n",
    "\n",
    "hs_cache = {}\n",
    "for row_i, row in tqdm(knowns_df.iterrows()):\n",
    "    prompt = row.prompt\n",
    "    inp = make_inputs(mt.tokenizer, [prompt])\n",
    "    \n",
    "    with nethook.TraceDict(\n",
    "        module=mt.model,\n",
    "        layers=layers_to_trace,\n",
    "        retain_input=True,\n",
    "        retain_output=True,\n",
    "        detach=True\n",
    "    ) as tr:\n",
    "        logits = mt.model(**inp).logits\n",
    "        predicted_token_index  = torch.argmax(torch.softmax(logits[:, -1, :], dim=-1), dim=-1)[0]\n",
    "        last_input = None\n",
    "        for layer in layers_to_trace:\n",
    "            if (prompt, layer) not in hs_cache:\n",
    "                hs_cache[(layer, prompt)] = {}\n",
    "                hs_cache[(layer,prompt)]['states'] = []\n",
    "                hs_cache[(layer,prompt)]['probs'] = []\n",
    "            \n",
    "            if 'attn' in layer:\n",
    "                hs_cache[(layer,prompt)]['states'].append(last_input)\n",
    "                hs_cache[(layer,prompt)]['states'].append(tr[layer].output[0][0] )\n",
    "            else:\n",
    "                last_input = tr[layer].input[0]\n",
    "                hs_cache[(layer,prompt)]['states'].append(last_input)\n",
    "                hs_cache[(layer,prompt)]['states'].append(tr[layer].output[0])\n",
    "            #compute attribute probs\n",
    "            hs_cache[(layer, prompt)]['probs'] = []\n",
    "            for i in range(2):\n",
    "                if i==1:\n",
    "                    full_repr = hs_cache[(layer,prompt)]['states'][i]+last_input\n",
    "                else:\n",
    "                    full_repr = hs_cache[(layer,prompt)]['states'][i]\n",
    "                log_probs = torch.softmax(ln_f(full_repr) @ E.T, dim = -1)\n",
    "                try:\n",
    "                    attr_log_probs = log_probs[-1, predicted_token_index]\n",
    "                except:\n",
    "                    attr_log_probs = log_probs.squeeze(0)[-1, predicted_token_index]\n",
    "                hs_cache[(layer, prompt)]['probs'].append(attr_log_probs.item())\n",
    "        \n",
    "len(hs_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sentence representations' similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T08:09:16.132143Z",
     "iopub.status.busy": "2024-04-04T08:09:16.131913Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "879it [05:09,  2.85it/s]"
     ]
    }
   ],
   "source": [
    "# Projection of token representations\n",
    "E = mt.model.get_input_embeddings().weight.detach()\n",
    "k = 50\n",
    "\n",
    "def jaccard_set(list1, list2):\n",
    "    \"\"\"Define Jaccard Similarity function for two sets\"\"\"\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "records = []\n",
    "all_probs = {}\n",
    "all_cos_sim_attn = [0 for l in layers_to_cache]\n",
    "all_cos_sim_mlp = [0 for l in layers_to_cache]\n",
    "all_jac_sim_attn = [0 for l in layers_to_cache]\n",
    "all_jac_sim_mlp = [0 for l in layers_to_cache]\n",
    "for row_i, row in tqdm(knowns_df.iterrows()):\n",
    "    prompt = row.prompt\n",
    "    subject = row.subject\n",
    "    attribute = row.attribute\n",
    "    \n",
    "    inp = make_inputs(mt.tokenizer, [prompt])\n",
    "    for layer in layers_to_trace:\n",
    "        layer_num = int(re.findall(\"\\d+\", layer)[0])\n",
    "        if layer not in all_probs:\n",
    "            all_probs[layer] = [0, 0]\n",
    "        if (layer,prompt) in hs_cache:\n",
    "            all_probs[layer][0] += hs_cache[(layer,prompt)]['probs'][0]\n",
    "            all_probs[layer][1] += hs_cache[(layer,prompt)]['probs'][1]\n",
    "        position, desc = (len(inp[\"input_ids\"][0])-1, f\"no_subj_last_{layer}\")\n",
    "        in_hs = hs_cache[(layer,prompt)]['states'][0][position]\n",
    "        try:\n",
    "            ot_hs = hs_cache[(layer,prompt)]['states'][1][position]\n",
    "        except:\n",
    "            ot_hs = hs_cache[(layer,prompt)]['states'][1].squeeze(0)[position]\n",
    "        in_projs = in_hs.matmul(E.T).cpu().numpy()\n",
    "        ot_projs = ot_hs.matmul(E.T).cpu().numpy()\n",
    "        in_ind = np.argsort(-in_projs)\n",
    "        ot_ind = np.argsort(-ot_projs)\n",
    "        in_topks = [decode_tokens(mt.tokenizer, [i])[0] for i in in_ind[:k]]\n",
    "        ot_topks = [decode_tokens(mt.tokenizer, [i])[0] for i in ot_ind[:k]]\n",
    "        \n",
    "        if \"mlp\" in layer:\n",
    "            all_cos_sim_mlp[layer_num] += torch.cosine_similarity(in_hs, ot_hs, dim = 0).cpu()\n",
    "            all_jac_sim_mlp[layer_num] += jaccard_set(in_topks, ot_topks)\n",
    "        else:\n",
    "            all_cos_sim_attn[layer_num] += torch.cosine_similarity(in_hs, ot_hs, dim = 0).cpu()\n",
    "            all_jac_sim_attn[layer_num] += jaccard_set(in_topks, ot_topks)\n",
    "        records.append({\n",
    "            \"example_index\": row_i,\n",
    "            \"subject\": subject,\n",
    "            \"layer\": layer,\n",
    "            \"position\": position,\n",
    "            \"desc\": desc,\n",
    "            \"desc_short\": desc.rsplit(\"_\", 1)[0],\n",
    "            \"input_top_k_preds\": in_topks,\n",
    "            \"output_top_k_preds\": ot_topks,\n",
    "        })\n",
    "\n",
    "tmp = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sim(layers_to_cache, ylabel, all_sim_attn, attn_label, all_sim_mlp, mlp_label, save_path=None):\n",
    "    layers_to_cache = [layer+1 for layer in layers_to_cache]\n",
    "    _, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    # Choose light colors for the lines\n",
    "    attn_color = 'skyblue'\n",
    "    mlp_color = 'lightcoral'\n",
    "    \n",
    "    # Plot attention similarity\n",
    "    plt.plot(layers_to_cache, np.array(all_sim_attn) / knowns_df_size, label=attn_label, color=attn_color, linestyle='-', marker='o', linewidth=2.5)\n",
    "    \n",
    "    # Plot MLP similarity\n",
    "    plt.plot(layers_to_cache, np.array(all_sim_mlp) / knowns_df_size, label=mlp_label, color=mlp_color, linestyle='--', marker='x', linewidth=2.5)\n",
    "    \n",
    "    plt.tick_params(labelsize=14)\n",
    "    labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "    [label.set_fontname('Times New Roman') for label in labels]\n",
    "\n",
    "    plt.xlabel('Layer', font1)\n",
    "    plt.ylabel(ylabel, font1)\n",
    "    plt.legend(loc='best', prop=font1)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()  # Ensures all elements fit nicely in the plot area\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='pdf')  # Save the plot as PDF file if the 'save_path' parameter is provided\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "font1 = {'family' : 'Times New Roman',\n",
    "'weight' : 'normal',\n",
    "'size'   : 14,\n",
    "}\n",
    "plot_sim(layers_to_cache, 'Average Cosine Similarity', all_cos_sim_attn,'Avg. Cos. Sim. - MHSA', all_cos_sim_mlp, 'Avg. Cos. Sim. - FFN', \"cos_sim.pdf\")\n",
    "plot_sim(layers_to_cache, 'Average Jaccard Similarity', all_jac_sim_attn,'Avg. Jac. Sim. - MHSA',all_jac_sim_mlp, 'Avg. Jac. Sim. - FFN', \"jac_sim.pdf\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python (pmet)",
   "language": "python",
   "name": "pmet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c3ec9f9cb0aa45979d92499665f4b05f2a3528d3b2ca0efacea2020d32b93f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
